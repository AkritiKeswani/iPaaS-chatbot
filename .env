# The Llama Cloud API key.
LLAMA_CLOUD_API_KEY=llx-AG6zpnB60tJtsyTbBBrbSmC13JZHTlx393l5aIZt46b2Hfaa

# The provider for the AI models to use.
MODEL_PROVIDER=openai

# The name of LLM model to use.
MODEL=gpt-3.5-turbo

# Name of the embedding model to use.
EMBEDDING_MODEL=text-embedding-3-large

# Dimension of the embedding model to use.
EMBEDDING_DIM=1536

# The questions to help users get started (multi-line).
# CONVERSATION_STARTERS=

# The OpenAI API key to use.
OPENAI_API_KEY=sk-proj-c54d6BiQplcm2r5YGudzT3BlbkFJo5XRM5tHNsuBJl8q2uZC

# Temperature for sampling from the model.
# LLM_TEMPERATURE=

# Maximum number of tokens to generate.
# LLM_MAX_TOKENS=

# The number of similar embeddings to return when retrieving documents.
TOP_K=3

# The time in milliseconds to wait for the stream to return a response.
STREAM_TIMEOUT=60000

# Configuration for Pinecone vector store
# The Pinecone API key.
PINECONE_API_KEY=6738058c-cfe3-41f2-b351-411af67e707d
PINECONE_ENVIRONMENT=us-east-1
PINECONE_INDEX_NAME=paragon-store

# FILESERVER_URL_PREFIX is the URL prefix of the server storing the images generated by the interpreter.
FILESERVER_URL_PREFIX=http://localhost:3000/api/files

# The system prompt for the AI model.
SYSTEM_PROMPT=You are a helpful assistant who helps users with their questions.

