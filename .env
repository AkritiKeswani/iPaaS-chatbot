# The Llama Cloud API key.
LLAMA_CLOUD_API_KEY=llx-AG6zpnB60tJtsyTbBBrbSmC13JZHTlx393l5aIZt46b2Hfaa

# The provider for the AI models to use.
MODEL_PROVIDER=openai

# The name of LLM model to use.
MODEL=gpt-3.5-turbo

# Name of the embedding model to use.
EMBEDDING_MODEL=text-embedding-3-large

# Dimension of the embedding model to use.
EMBEDDING_DIM=1024

# The questions to help users get started (multi-line).
# CONVERSATION_STARTERS=

# The OpenAI API key to use.
OPENAI_API_KEY=sk-proj-c54d6BiQplcm2r5YGudzT3BlbkFJo5XRM5tHNsuBJl8q2uZC

PARAGON_SIGNING_KEY=MIIJQQIBADANBgkqhkiG9w0BAQEFAASCCSswggknAgEAAoICAQCf3YxUXsZtvTrE
gqy1mKgjIJCsxXxC+KOoGDXl4Ik+UJU4+dpQWSXgmSyKEsvXmAxo297Ns1fafRkj
NIjNfLJ87yF3q5K4lz89UUihs8RW82zJ+AYk4cn5rjJ+5oNbYns9e7p75F6Syc+K
5BaUcheeL9z/N1p6lYvvDtlSerN/isHL5qAymQdzjjcUrv5KbXNIB23eb25A9Cyt
mFBw+++uzFd0+9rrLFb2I6n67/7F0tj4jrqULq0D0iMZUkPAcoO63VX7zQ0tTaNS
EuAvrQamExi8MDRXnrhdeCXpUqcwdcCBzzVrsUKdkuM6WDtSSXPQgXuKtG/nNMU3
QZqjlTeimY07Srm5KDdaV6W7yAMlGLqPgW3fMyKppF9gUjOSF4NlXl81ULEVCUVl
9v4dee7f1c0a+YMTj8qTguJYy3AyIdOa9PXfrm1iYbukco+oFtVnGjqvuQfnBv44
W+37fisXbp5peNhDvb/olLBUC9UHGamCjVQqMJZfs8XNerCCfd5x0SxzqSeeEOTZ
weawIme3RlWIuAP+JeEChNTckZjHZ/K4bUiqKVAJUSbVO9lYTOPrU9C6BWZvN0Ve
adIB7cKJue6ByQOW9CizDS3kBAE+wFY8jVbkkoSw4JDLGLABHBthI5+wBBeDCWEa
5sjaP7AHfIL9m6IqBM9w5XHXke59bQIDAQABAoICAA5TA2cu69A676hafh+ya0Rk
f1ofwuPcVAu0iaXMofeFsG0/w/5FkqWGjA1eJEov21LM+rCLRJC0+1ricuyYowSb
R7ApnTaxhK7ZmOy2Rx40ZxfMw74rxhV7dJZW0MfQMfM/IiVGP+werZxIFjbcZz3b
E44Bt3d67WQw/CuOB4Xi2L0Mr+eAu0BxKoHNsUbZekYmtkNDUEl9J4CxgGmzRVVw
BVkb1RCT80HQTcOInBc9LohM/65V5VZNjqwO6Te1+xQ0D2eFxsu7pGnu+4wCELGy
TdnU5ue/9syXPqxipczrjCGFf8ejxTCJ0Bby/3O+1aQF6hwyUUGSAqbSF8lXDjo8
++LvP2Fd53DvazUgC3vL5mNCK91MvKr3rl+5XAsVdNWypl+39nUAZag/vWFZeJcg
Z+L7flfmWG4LQzxSqBsv4D8UTuDNVFdszCZBOMUXahrglhLWB8XxkuS9CTWRHdw/
LM8mBiQl7guCAxBdlqv3OOWexjZN8tb+IF44cT16p1OOYa6tVhNe+VaqUfEvXcWp
/TYnIIW0xb++qzfSZh3hZ7HR17pEmQ8xccR6H7n8izcMw2O9/idXPqspPxEb6siL
tfcwvpw9XiWeJ0PFPPCE8VTJG/PLhfh5bflIHj29zI+rX+5V+Mot9d1lpE81w+oh
K+ALS8hIfz/HzRvgs/DhAoIBAQC9jFj+5V0A3aUHgXb4NyvD4mKDeCzNKDFapSRh
l6/uOmFugLRjBV/07TlPRm2uR4U7BImaTSBAhXMp7PtSMM11OnGZSEgl6/HGfMF1
ZmtSNyI7GXW05n4RHCtf0X7cxLnpQqkz+5z+Sl7qmbHyV9gk3qPeE+4DDvM5GH4B
uONHplHRTiGkslFw9Iec4HWnKSB8PWta8JzxcVlPC2QRYu3Axww0GCtvUb22I9Ez
OTfRE2l16RgkTuNNYTW7wY5Inr7McfcUzGVDwp8YVcJwIGyqgjd06gmEONnF6zyI
SCX1ZoB73nLe6qqn6ewE6UpFWffSF/4+PCtjKAVI3GFtwV+hAoIBAQDX6TcrafYx
1+aPP/t5YEeccOSAiC1JsphFe+A0wgJ3D+Cok9ec768oLFVa/u1/6QZ9DRqXjcbm
aPSMTRA6a2uE9mm2ccktwbLSLATKnJvDni4VvtNS6Z7fSUJFj12hlpvnVd+ZZAGF
LN4o4YdyD65/Zb9ddp3CCh+taqZPlih5kiZxRSWxB0SJJrtrWV0X3GaxYZ7Qj9FR
aCw88vZomz1dS7obUyuAKU+PxBnTMOwlqYeGMc8MdmfEWwvVsWZAUgmeC5S18j/e
hu1lAhKf3lioKTHAA+1P8ETyGxGNQUUS93hYsO+jRJN31rSp7pvuNhxZGje8h63c
Gjch01Nh8npNAoIBAG0wA7QRe9mb1AzWzyl83oEgT49cErK7jHKi3qo5LucUSjvV
eBPybKwyWukHsPbLzDuLCZkRBJsmRIjKMpvN8QyudfHOaYEuwT+NbgOq0/ewOs/A
gsWKYOSKTZIMo/+Yc1+jPsTrFCyHutV5Y8AuShwzBEJRSLIKUqF5MlzbnFERxd/E
Gi09axyeP+BmjF+WmVf4KXdhU4bhvIiED0jUrBB4mNcJdTvS4m2hhEj1lOmjPQTn
GTkRGG7iqIlXnhbHGzG6FJKui0bVPcBO5oqgovg1uqxmhMTd2tTgBSacKQGL4kd4
hMNUeqnvXj4WBOqeQNuNZq+DCZs82o52JMmMswECggEAaWrGsv2zZLajLYHxyFtH
24wLJO5YHkmCqzpGR7wJ9BPefrBgb5FfFeA/dIRPdUpTDq9dMm3YlRrde7sMl1ln
T634A0ofDaYrJw6y8DHyo1oR6jAXgb3rAd4E622KK6EbUaHN4FjBnUJA3fjvZrNd
YXpOKtYFRH4o5UTTGryX2nOPLXKzanG/9q7ghxNErqe/xA+DuRTfAD46iy+dO4nA
NlMI9NpwvMxuuiTm7wRN6D2Tm+Op0c3l8Cr75kQNRo5Hf9DrtMIoiP+b3NtcOI4Y
/1HNppDER2lqYELzGOKrVQ1axwLsneyXi8VaxDVqEK5+vMpeOECOlI6AKJXDemkn
aQKCAQA/FpbdoBytPNoZ4YelwbhIR4+lSRH2p4LwEEuiXmz/Q5alKF6HdMYhNc3r
vwxNo8qiSW72S31eBhKkVPDkj5WkqKMxZkSJjt5r/sdaXEYmwBvVl/+Fl8a2VNyQ
FymaM3XCFl/tVRWnBvSVkbQkY2KEPh7mhIqqU4iff1dYYjEfndzShN/Aitj9wlir
oLWheLW3RfTC2pI9a3B3lZffMBLxWlPyaAc7tD+pc7Yu0UtL2jF6bwldnkvG3dgr
3Lew78EvTuQ8FM3RCoOTqcpjmm6xnmKPZ31lBSB0mlp87C0R5esrN+Eu3BC4tlxE
rjwgee16j6Ii4Ond/X5mqA1kU9fe

# Temperature for sampling from the model.
# LLM_TEMPERATURE=

# Maximum number of tokens to generate.
# LLM_MAX_TOKENS=

# The number of similar embeddings to return when retrieving documents.
TOP_K=3

# The time in milliseconds to wait for the stream to return a response.
STREAM_TIMEOUT=60000

# Configuration for Pinecone vector store
# The Pinecone API key.
PINECONE_API_KEY=6738058c-cfe3-41f2-b351-411af67e707d 

PINECONE_ENVIRONMENT=us-east-1

PINECONE_INDEX_NAME=paragon-store

# FILESERVER_URL_PREFIX is the URL prefix of the server storing the images generated by the interpreter.
FILESERVER_URL_PREFIX=http://localhost:3000/api/files

# The system prompt for the AI model.
SYSTEM_PROMPT=You are a helpful assistant who helps users with their questions.

